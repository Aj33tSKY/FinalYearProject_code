{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0d0b3a-a3e6-4d64-9d99-e6fc81ff5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a677a7-b97a-4ad8-91ec-bfab66be982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cf3243-7031-4d0b-bf65-7819275572b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Stable', 'Unstable']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"4B-2D-Uni\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d4484fc-437d-4a91-aefa-9c363293dcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda\\envs\\FPY_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\tools\\Anaconda\\envs\\FPY_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\ajeet/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load model: densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 30.8M/30.8M [00:05<00:00, 5.59MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from transformers import AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_feature_extractor(model_name):\n",
    "    print(f\"Attempting to load model: {model_name}\")\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1]) \n",
    "        \n",
    "    elif model_name == \"alexnet\":\n",
    "        model = models.alexnet(pretrained=True)\n",
    "        feature_extractor = model.features  \n",
    "    \n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        feature_extractor = model.features\n",
    "    \n",
    "    elif model_name == \"densenet121\":\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    elif model_name == \"densenet169\":\n",
    "        model = models.densenet169(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    elif model_name == \"densenet201\":\n",
    "        model = models.densenet201(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    elif model_name == \"googlenet\":\n",
    "        model = models.googlenet(pretrained=True)\n",
    "        feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    elif model_name == \"inception_v3\":\n",
    "        model = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "        model.fc = nn.Identity()\n",
    "        feature_extractor = model\n",
    "    \n",
    "    # EfficientNet models\n",
    "    elif model_name in [\"efficientnet-b0\", \"efficientnet-b1\", \"efficientnet-b2\", \n",
    "                         \"efficientnet-b3\", \"efficientnet-b4\", \"efficientnet-b5\", \n",
    "                         \"efficientnet-b6\", \"efficientnet-b7\"]:\n",
    "        model = EfficientNet.from_pretrained(model_name)\n",
    "        feature_extractor = model\n",
    "    \n",
    "    # EfficientNetV2 models using timm\n",
    "    elif model_name in [\"tf_efficientnetv2_b0\", \"efficientnetv2_b1\", \"efficientnetv2_s\"]:\n",
    "        # EfficientNetV2 from timm\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        feature_extractor = model\n",
    "\n",
    "    # ConvNeXt models\n",
    "    elif model_name in [\"convnext_tiny\", \"convnext_small\", \"convnext_base\", \"convnext_large\"]:\n",
    "        # Load ConvNeXt from timm\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        feature_extractor = model\n",
    "\n",
    "\n",
    "    # ConvNeXtV2 models\n",
    "    elif model_name in [\"convnextv2_tiny\", \"convnextv2_small\", \"convnextv2_base\", \"convnextv2_large\"]:\n",
    "        # Load ConvNeXtV2 from timm\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        feature_extractor = model\n",
    "\n",
    "    # DEIT models\n",
    "    elif model_name in [\"deit_tiny_patch16_224\", \"deit_small_patch16_224\", \"deit_base_patch16_224\"]:\n",
    "        # Load DEIT from timm\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        feature_extractor = model\n",
    "\n",
    "    # ViT models\n",
    "    elif model_name in [\"vit_tiny_patch16_224\", \"vit_small_patch16_224\", \"vit_base_patch16_224\", \"vit_large_patch16_224\"]:\n",
    "        # Load ViT from timm\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        feature_extractor = model\n",
    "\n",
    "    # DINOv2 models\n",
    "    elif model_name == \"dino_vits\":\n",
    "        model = AutoModel.from_pretrained(\"facebook/dinov2-small\").to(device)\n",
    "        feature_extractor = model\n",
    "\n",
    "\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    feature_extractor = feature_extractor.to(device)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "# Example of calling the function with EfficientNetV2-S (from timm) with random weights or pretrained weights\n",
    "#feature_extractor = get_feature_extractor(\"tf_efficientnetv2_b0\")  # Use pretrained EfficientNetV2-B0\n",
    "#feature_extractor = get_feature_extractor(\"convnext_tiny\")  # ConvNeXt-Tiny from timm\n",
    "\n",
    "#feature_extractor = get_feature_extractor(\"convnextv2_tiny\")\n",
    "#feature_extractor = get_feature_extractor(\"deit_base_patch16_224\")\n",
    "#feature_extractor = get_feature_extractor(\"vit_base_patch16_224\")\n",
    "#feature_extractor = get_feature_extractor(\"dino_vits\")\n",
    "#feature_extractor = get_feature_extractor(\"efficientnet-b1\")\n",
    "#feature_extractor = get_feature_extractor(\"resnet18\")\n",
    "feature_extractor = get_feature_extractor(\"densenet121\")\n",
    "\n",
    "print(\"Feature extractor initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d2d8537-9a83-4c1c-80cc-f69b72254e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "def extract_features(data_loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, label in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)  # Extract features\n",
    "            output = output.view(output.size(0), -1)  # Flatten\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "# Extract features from datasets\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor)\n",
    "val_features, val_labels = extract_features(val_loader, feature_extractor)\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor)\n",
    "\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712a52d8-d3d7-4fbd-98bf-558e1f1bfc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "#ONLY FOR DINOv2\n",
    "def extract_features(data_loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, label in data_loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            \n",
    "            output = model(images)\n",
    "\n",
    "            output = output.pooler_output  \n",
    "\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor)\n",
    "val_features, val_labels = extract_features(val_loader, feature_extractor)\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor)\n",
    "\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "85762166-9e2c-4642-8dfa-2b1dc42c0690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8950\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "# Train\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(train_features, train_labels)\n",
    "\n",
    "# Validate\n",
    "val_preds = svm.predict(val_features)\n",
    "val_acc = accuracy_score(val_labels, val_preds)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1f89dfe-8f97-45aa-a870-50704dec6186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_preds = svm.predict(test_features)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ffab121-7771-464b-a800-36d6ac70316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test Classes: ['Stable', 'Unstable']\n",
      "New Test Accuracy: 0.6100\n"
     ]
    }
   ],
   "source": [
    "new_test_dir = \"10B-2D-Uni/test\"\n",
    "\n",
    "# Load the new test dataset\n",
    "new_test_dataset = datasets.ImageFolder(new_test_dir, transform=transform)\n",
    "new_test_loader = DataLoader(new_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"New Test Classes: {new_test_dataset.classes}\")\n",
    "\n",
    "new_test_features, new_test_labels = extract_features(new_test_loader, feature_extractor)\n",
    "\n",
    "new_test_features = scaler.transform(new_test_features)\n",
    "\n",
    "new_test_preds = svm.predict(new_test_features)\n",
    "\n",
    "new_test_acc = accuracy_score(new_test_labels, new_test_preds)\n",
    "print(f\"New Test Accuracy: {new_test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ac1af-5a61-49bf-80bc-fca1fd74b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a988f7-9966-4a09-984d-e204b0455482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FPY_env]",
   "language": "python",
   "name": "conda-env-FPY_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
